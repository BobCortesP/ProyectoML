{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14ab511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Input, Embedding, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80438a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializar y abrir archivo\n",
    "corpus=[]\n",
    "target=[]\n",
    "edad=[]\n",
    "sexo=[]\n",
    "severidad=[]\n",
    "archivo=open(\"dataset_elpino.csv\",encoding=\"utf-8\")\n",
    "\n",
    "#Sacar las variables (features o característica)\n",
    "header=archivo.readline().strip().split(\";\")\n",
    "features=[]\n",
    "for col in header:\n",
    "    if col.startswith(\"Diag\") or col.startswith(\"Proc\"):\n",
    "        col=col.split(\" \")\n",
    "        col=col[0]+col[1]\n",
    "    features.append(col)\n",
    "\n",
    "#Sacar la data (deja sólo los códigos en el corpus)\n",
    "for linea in archivo:\n",
    "    row=[]\n",
    "    linea=linea.strip().split(\";\")\n",
    "    for i in range(len(linea)):\n",
    "        col=linea[i].split(\"-\")[0].strip()\n",
    "        if i==67:\n",
    "            grd=col\n",
    "            #target.append(grd[-1])\n",
    "            target.append(grd)\n",
    "        elif i==66:\n",
    "            sexo.append(1 if col==\"Mujer\" else 0)\n",
    "        elif i==65:\n",
    "            edad.append(int(col))\n",
    "        else:\n",
    "            row.append(col)\n",
    "    corpus.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e207b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el dataframe\n",
    "df=pd.DataFrame(corpus,columns=features[:-3])\n",
    "df[\"GRD\"]=target\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be23bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construirModelo(n):\n",
    "    filtro_lst = list(dict(df[\"GRD\"].value_counts()[:]).keys())[:n]\n",
    "    filtro={filtro_lst[j]: [1 if (filtro_lst[j] == i) else 0 for i in filtro_lst] for j in range(len(filtro_lst))}\n",
    "\n",
    "    # Crear los X's y los Y's\n",
    "    seed=12122008\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    vocabulario={}\n",
    "    for linea in range(len(corpus)):\n",
    "        message=[]\n",
    "        if target[linea] in filtro.keys():\n",
    "            for j in corpus[linea]:\n",
    "                message.append(j)\n",
    "                if j in vocabulario:\n",
    "                    vocabulario[j]+=1\n",
    "                else:\n",
    "                    vocabulario[j]=1\n",
    "            X.append(message)\n",
    "            Y.append(filtro[target[linea]])\n",
    "\n",
    "    # Tokenizar el texto\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    sequences = tokenizer.texts_to_sequences(X)\n",
    "    words=list(tokenizer.word_index.keys())\n",
    "\n",
    "    vocabulary=len(words)+1\n",
    "    X = sequences\n",
    "    # Convertir los 1 en 0 para que no se cuenten como palabras\n",
    "    sequences_array = np.array(X)\n",
    "    sequences_array[sequences_array == 1] = 0\n",
    "    X = sequences_array.tolist()\n",
    "\n",
    "    input_length=len(X[0])\n",
    "\n",
    "    X=np.asarray(X)\n",
    "    Y=np.asarray(Y)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=seed)\n",
    "    modelo_gru = Sequential()\n",
    "    modelo_gru.add(Embedding(input_dim=vocabulary, output_dim=64))  # Embedding para códigos\n",
    "    modelo_gru.add(GRU(64, return_sequences=False, activation=\"relu\"))  # GRU con 64 unidades\n",
    "    modelo_gru.add(Dense(len(filtro_lst), activation=\"softmax\"))  # Capa de salida\n",
    "    modelo_gru.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return modelo_gru, x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4115fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con 20 GRD\n",
      "Accuracy:  0.9428815245628357\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Entrenando modelo con 40 GRD\n",
      "Accuracy:  0.9182782173156738\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "Entrenando modelo con 60 GRD\n",
      "Accuracy:  0.8622915744781494\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 80 GRD\n",
      "Accuracy:  0.8528265357017517\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 100 GRD\n",
      "Accuracy:  0.8526886701583862\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Entrenando modelo con 120 GRD\n",
      "Accuracy:  0.849743127822876\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Entrenando modelo con 140 GRD\n",
      "Accuracy:  0.7976141571998596\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 160 GRD\n",
      "Accuracy:  0.7831805348396301\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Entrenando modelo con 180 GRD\n",
      "Accuracy:  0.747863233089447\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Entrenando modelo con 200 GRD\n",
      "Accuracy:  0.7632279992103577\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 220 GRD\n",
      "Accuracy:  0.7205387353897095\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 240 GRD\n",
      "Accuracy:  0.7440059185028076\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 260 GRD\n",
      "Accuracy:  0.7468124032020569\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 280 GRD\n",
      "Accuracy:  0.7524324059486389\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 300 GRD\n",
      "Accuracy:  0.7528571486473083\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Entrenando modelo con 320 GRD\n",
      "Accuracy:  0.7219858169555664\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 340 GRD\n",
      "Accuracy:  0.7374911904335022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Entrenando modelo con 360 GRD\n",
      "Accuracy:  0.7245970368385315\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Entrenando modelo con 380 GRD\n",
      "Accuracy:  0.7163293957710266\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Entrenando modelo con 400 GRD\n",
      "Accuracy:  0.6941258311271667\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Entrenando modelo con 420 GRD\n",
      "Accuracy:  0.7251299619674683\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = dict()\n",
    "for i in  range(20, 421, 20):\n",
    "    print(\"Entrenando modelo con {} GRD\".format(i))\n",
    "    modelo, x_train, y_train, x_val, y_val = construirModelo(i)\n",
    "    modelo.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=32, verbose=0)\n",
    "    print(\"Accuracy: \", modelo.history.history[\"val_accuracy\"][-1])\n",
    "    y_pred_probs[i] = modelo.predict(x_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
